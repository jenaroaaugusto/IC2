{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Algorítimos para SBCM 2019.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNjlRJrNvd2iZWZv/zGg0Ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenaroaaugusto/IC2/blob/master/Algor%C3%ADtimos_para_SBCM_2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNjAXcc1RJJk",
        "colab_type": "text"
      },
      "source": [
        "#Definição de bibliotecas\n",
        "Definição das bibliotecas e sobre a leitura dos dados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9w028g_X6rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import neighbors, metrics\n",
        "import time\n",
        "import os \n",
        "import os\n",
        "import pathlib\n",
        "from sklearn.datasets import load_sample_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHx0JYPGPtol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e839d281-96ce-4d9d-9560-0d62654cf8dc"
      },
      "source": [
        "!rm -r  \"/content/Music_Symbols/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/Music_Symbols/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKJqsFDFV_y4",
        "colab_type": "code",
        "outputId": "f37cd359-c3bb-4a9a-d37f-4de2f75f404f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!git clone https://github.com/jenaroaaugusto/Music_Symbols.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Music_Symbols'...\n",
            "remote: Enumerating objects: 4174, done.\u001b[K\n",
            "remote: Counting objects: 100% (4174/4174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2720/2720), done.\u001b[K\n",
            "remote: Total 4174 (delta 1468), reused 4151 (delta 1452), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4174/4174), 2.91 MiB | 13.17 MiB/s, done.\n",
            "Resolving deltas: 100% (1468/1468), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz4gHK5FWEZP",
        "colab_type": "code",
        "outputId": "c8b574fc-93d5-4303-d6b5-622d6396476b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls \"/content/Music_Symbols\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conjunto  Imagens  Notas.zip  README.md  Readme_Symbols.txt  Separadas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLyJibCPWSrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "zf = ZipFile('/content/Music_Symbols/Notas.zip', 'r')\n",
        "zf.extractall()\n",
        "zf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gpd2dTWzOy",
        "colab_type": "code",
        "outputId": "e1fa7f2b-14d7-4ba0-d114-f73b35fcbe38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls \"/content/\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ImagensAlvo_B.txt  Imagens_B.txt  Music_Symbols  TestesAlvo_B.txt  Testes_B.txt\n",
            "ImagensAlvo_C.txt  Imagens_C.txt  sample_data\t TestesAlvo_C.txt  Testes_C.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wquft8s_N4yQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arq_imagens = open('/content/Imagens_C.txt', 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHb411qhOIM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.loadtxt(arq_imagens)\n",
        "notess = data.view()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-8-wn4sOlgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from os import listdir\n",
        "# from os.path import isfile, join\n",
        "# import re\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# mypath = '/content/Music_Symbols/conjunto/train' # edit with the path to your data\n",
        "\n",
        "# files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "\n",
        "# print(files)\n",
        "\n",
        "# x = []\n",
        "# y = []\n",
        "\n",
        "# for file in files:\n",
        "#     label = file.split('_')[0] # assuming your img is named like this \"eight_1.png\" you want to get the label \"eight\"\n",
        "#     y.append(label)\n",
        "#     img = plt.imread(file)\n",
        "#     x.append(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWUpefe_doK0",
        "colab_type": "code",
        "outputId": "53a58945-8677-4980-e1c2-616ccd9d325c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "trainDir = os.path.join('/content/Music_Symbols/conjunto', 'train')\n",
        "train_dir = pathlib.Path(\"\"+trainDir)\n",
        "print(train_dir)\n",
        "total_train = len(list(train_dir.glob('*/*.bmp')))\n",
        "print(total_train)\n",
        "CLASS_NAMES=np.array(os.listdir(train_dir))\n",
        "print(CLASS_NAMES)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Music_Symbols/conjunto/train\n",
            "3271\n",
            "['ACCIDENTAL_Flat' 'ACCIDENTAL_DoubSharp' 'CLEF_Trebble' 'CLEF_Bass'\n",
            " 'CLEF_Alto' 'ACCIDENTAL_Natural' 'ACCIDENTAL_Sharp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOIC3kfrYdJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e433e679-12a7-4c49-c1e9-449ff7b68eb4"
      },
      "source": [
        "testDir= os.path.join('/content/Music_Symbols/conjunto','val')\n",
        "test_dir = pathlib.Path(\"\"+testDir)\n",
        "print(test_dir)\n",
        "total_test = len(list(test_dir.glob('*/*.bmp')))\n",
        "print(total_test)\n",
        "CLASS_NAMEST=np.array(os.listdir(test_dir))\n",
        "print(CLASS_NAMEST)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Music_Symbols/conjunto/val\n",
            "822\n",
            "['ACCIDENTAL_Flat' 'ACCIDENTAL_DoubSharp' 'CLEF_Trebble' 'CLEF_Bass'\n",
            " 'CLEF_Alto' 'ACCIDENTAL_Natural' 'ACCIDENTAL_Sharp']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRhN7CPAEnUO",
        "colab_type": "code",
        "outputId": "69c34c39-2abd-463e-dcc2-73e2cc4d5ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CLASS_NAMES[0]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ACCIDENTAL_Flat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcDie3TG4gjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes=[]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhfh5kx7Gkds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r  \"/content/Music_Symbols/\"\n",
        "from skimage import io\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from sklearn.datasets import load_sample_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JsU1z1bleG-",
        "colab_type": "code",
        "outputId": "251ebf41-bd49-4acf-d6f5-918f6d8067b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "for i in train_dir.iterdir():\n",
        "  print(i)\n",
        "  labea=np.array(os.listdir(i))\n",
        "  print(len(labea))\n",
        "  for j in i.iterdir():\n",
        "    img = cv2.imread(j)\n",
        "    img=img=cv2.resize(img,(28, 28), interpolation = cv2.INTER_AREA)\n",
        "    # print(img.shape)\n",
        "    if img.shape==(28,28):\n",
        "      notes.append(img)\n",
        "    else:\n",
        "      print(\"Erro\")\n",
        "      print(j)\n",
        "      print(img.shape)\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Music_Symbols/conjunto/train/ACCIDENTAL_Flat\n",
            "413\n",
            "/content/Music_Symbols/conjunto/train/ACCIDENTAL_DoubSharp\n",
            "397\n",
            "/content/Music_Symbols/conjunto/train/CLEF_Trebble\n",
            "656\n",
            "Erro\n",
            "/content/Music_Symbols/conjunto/train/CLEF_Trebble/sol10.bmp\n",
            "(28, 28, 3)\n",
            "/content/Music_Symbols/conjunto/train/CLEF_Bass\n",
            "439\n",
            "/content/Music_Symbols/conjunto/train/CLEF_Alto\n",
            "607\n",
            "/content/Music_Symbols/conjunto/train/ACCIDENTAL_Natural\n",
            "376\n",
            "/content/Music_Symbols/conjunto/train/ACCIDENTAL_Sharp\n",
            "384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkaMnOf4I48F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3e76872f-69cb-461a-f609-b12fd9bdf77a"
      },
      "source": [
        "len(notes)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3270"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtneSj1aLicD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_notes=[]\n",
        "for i in range(413):\n",
        "  target_notes.append(0)\n",
        "\n",
        "for j in range(397):\n",
        "  target_notes.append(1)\n",
        "\n",
        "for k in range(654):\n",
        "  target_notes.append(2)\n",
        "\n",
        "for l in range(439):\n",
        "  target_notes.append(3)\n",
        "\n",
        "for m in range(607):\n",
        "  target_notes.append(4)\n",
        "\n",
        "for n in range(376):\n",
        "  target_notes.append(5)\n",
        "\n",
        "for o in range(384):\n",
        "  target_notes.append(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW32q3ZxqGTm",
        "colab_type": "code",
        "outputId": "ec12b170-1185-4991-d911-d300db21981c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(target_notes))\n",
        "\n",
        "target_notes = np.array(target_notes)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShXroUtCWu8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes = np.array(notes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUJMS57-WzND",
        "colab_type": "code",
        "outputId": "31e9f13f-b652-40db-9033-d22c3e2c4812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "notes.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3270, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDn-HtUtr_zF",
        "colab_type": "code",
        "outputId": "df75131c-e68a-4639-d396-3b3df0819d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_notes.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3270,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N6y51ArZUvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes_test=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9OUN1N7YCPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b73b5546-1d1b-4fd1-8a71-980ced03ea5e"
      },
      "source": [
        "for i in test_dir.iterdir():\n",
        "  print(i)\n",
        "  labea=np.array(os.listdir(i))\n",
        "  print(len(labea))\n",
        "  for j in i.iterdir():\n",
        "    img = cv2.imread(j)\n",
        "    img=img=cv2.resize(img,(28, 28), interpolation = cv2.INTER_AREA)\n",
        "    # print(img.shape)\n",
        "    if img.shape==(28,28):\n",
        "      notes_test.append(img)\n",
        "    else:\n",
        "      print(\"Erro\")\n",
        "      print(j)\n",
        "      print(img.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Music_Symbols/conjunto/val/ACCIDENTAL_Flat\n",
            "104\n",
            "/content/Music_Symbols/conjunto/val/ACCIDENTAL_DoubSharp\n",
            "100\n",
            "/content/Music_Symbols/conjunto/val/CLEF_Trebble\n",
            "164\n",
            "/content/Music_Symbols/conjunto/val/CLEF_Bass\n",
            "110\n",
            "/content/Music_Symbols/conjunto/val/CLEF_Alto\n",
            "152\n",
            "/content/Music_Symbols/conjunto/val/ACCIDENTAL_Natural\n",
            "95\n",
            "/content/Music_Symbols/conjunto/val/ACCIDENTAL_Sharp\n",
            "97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDfoAoN2Z8cw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes_test=np.array(notes_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwdvZZpTZOjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_test=[]\n",
        "for i in range(104):\n",
        "  target_test.append(0)\n",
        "\n",
        "for j in range(100):\n",
        "  target_test.append(1)\n",
        "\n",
        "for k in range(164):\n",
        "  target_test.append(2)\n",
        "\n",
        "for l in range(110):\n",
        "  target_test.append(3)\n",
        "\n",
        "for m in range(152):\n",
        "  target_test.append(4)\n",
        "\n",
        "for n in range(95):\n",
        "  target_test.append(5)\n",
        "\n",
        "for o in range(97):\n",
        "  target_test.append(6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF6QQYmtaGfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_test=np.array(target_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud_12QVAZ1vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e60a590b-ab42-4420-fe1f-9e28e2aedc77"
      },
      "source": [
        "target_test.shape\n",
        "\n",
        "notes_test.shape"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(822, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFRUlgmMX2K4",
        "colab_type": "text"
      },
      "source": [
        "#Testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7HPSHfo24g2",
        "colab_type": "code",
        "outputId": "1403862b-6092-439d-baf4-bda843356a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# The data that we are interested in is made of 8x8 images of digits, let's\n",
        "# have a look at the first 4 images, stored in the `images` attribute of the\n",
        "# dataset.  If we were working from image files, we could load them using\n",
        "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
        "# images, we know which digit they represent: it is given in the 'target' of\n",
        "# the dataset.\n",
        "_, axes = plt.subplots(2, 5)\n",
        "images_and_labels = list(zip(xy, legendas))\n",
        "# print(digits.images[0])\n",
        "# print(digits.target.shape)\n",
        "\n",
        "for ax, (image, label) in zip(axes[0, :], images_and_labels[:8]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Training: %i' % label)\n",
        "\n",
        "# To apply a classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(arr)\n",
        "data = arr.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Split data into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, legendas, test_size=0.5, shuffle=False)\n",
        "\n",
        "# We learn the digits on the first half of the digits\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = classifier.predict(X_test)\n",
        "\n",
        "images_and_predictions = list(zip(arr[n_samples // 2:], predicted))\n",
        "for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Prediction: %i' % prediction)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Classification report for classifier SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "           3       0.00      0.00      0.00     479.0\n",
            "           4       0.00      0.00      0.00     376.0\n",
            "           5       0.00      0.00      0.00     397.0\n",
            "           6       0.00      0.00      0.00     384.0\n",
            "\n",
            "    accuracy                           0.00    1636.0\n",
            "   macro avg       0.00      0.00      0.00    1636.0\n",
            "weighted avg       0.00      0.00      0.00    1636.0\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            "[[  0   0   0   0   0]\n",
            " [479   0   0   0   0]\n",
            " [376   0   0   0   0]\n",
            " [397   0   0   0   0]\n",
            " [384   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIuJJ5Al1Nt2",
        "colab_type": "text"
      },
      "source": [
        "#Novo carregar dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdiLF-5PW7A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def carrega_dados():\n",
        "  trainDir = os.path.join('/content/Music_Symbols/conjunto', 'train')\n",
        "  train_dir = pathlib.Path(\"\"+trainDir)\n",
        "  print(train_dir)\n",
        "  total_train = len(list(train_dir.glob('*/*.bmp')))\n",
        "  print(total_train)\n",
        "  CLASS_NAMES=np.array(os.listdir(train_dir))\n",
        "  print(CLASS_NAMES)\n",
        "  testDir= os.path.join('/content/Music_Symbols/conjunto','val')\n",
        "  test_dir = pathlib.Path(\"\"+testDir)\n",
        "  print(test_dir)\n",
        "  total_test = len(list(test_dir.glob('*/*.bmp')))\n",
        "  print(total_test)\n",
        "  CLASS_NAMEST=np.array(os.listdir(test_dir))\n",
        "  print(CLASS_NAMEST)\n",
        "\n",
        "    return notes, notes_test, target_notes, target_test\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y81Sur1nX7Ps",
        "colab_type": "text"
      },
      "source": [
        "#Carrega_dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Co72rZGzRkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def carrega_dados():\n",
        "#     # Arquico que contém Imagens\n",
        "#     arq_imagens = open('/content/Imagens_C.txt', 'r')\n",
        "#     # Arquivo que contém Imagens para Teste\n",
        "#     arq_teste = open('/content/Testes_C.txt', 'r')\n",
        "#     # Arquivo que contém alvo das Imagens\n",
        "#     arq_alvo_imagens = open('/content/ImagensAlvo_C.txt', 'r')\n",
        "#     # Arquivo que contém alvo das Imagens para Teste\n",
        "#     arq_alvo_testes = open('/content/TestesAlvo_C.txt', 'r')\n",
        "\n",
        "\n",
        "#     # Carregando Imagens\n",
        "#     data = np.loadtxt(arq_imagens)\n",
        "#     notes = data.view()\n",
        "#     notes.shape = (-1, 24, 24)\n",
        "#     arq_imagens.close()\n",
        "#     # print(notes[0])\n",
        "#     # print(notes[1])\n",
        "\n",
        "#     # Carreagando Images para Teste\n",
        "#     data = np.loadtxt(arq_teste)\n",
        "#     notes_test = data.view()\n",
        "#     notes_test.shape = (-1, 24, 24)\n",
        "#     arq_teste.close()\n",
        "#     # print(notes_test[0])\n",
        "#     # print(notes_test[1])\n",
        "\n",
        "#     # Carregando alvo das Imagens\n",
        "#     data = np.loadtxt(arq_alvo_imagens)\n",
        "#     target_notes = data.view().astype(np.int)\n",
        "#     arq_alvo_imagens.close()\n",
        "#     # print(target_notes[0])\n",
        "#     # print(target_notes[1])\n",
        "\n",
        "#     # Carregando alvo das Imagens para teste\n",
        "#     data = np.loadtxt(arq_alvo_testes)\n",
        "#     target_test = data.view().astype(np.int)\n",
        "#     arq_alvo_testes.close()\n",
        "#     # print(target_test[0])\n",
        "#     # print(target_test[1])\n",
        "\n",
        "#     return notes, notes_test, target_notes, target_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25kOqqgNa3Mc",
        "colab_type": "text"
      },
      "source": [
        "#Algortimo SVM_Notas\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDxmo92JYViW",
        "colab_type": "code",
        "outputId": "bf9af9b8-f107-422d-9cbe-5841b165098b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "from sklearn import svm, metrics\n",
        "# = carrega_dados()\n",
        "# notes, notes_test, target_notes, target_test \n",
        "\n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vetores de suporte\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Aprendemos os dígitos na primeira metade dos dígitos\n",
        "\n",
        "classifier.fit(data, target_notes)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = classifier.predict(data_teste)\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       104\n",
            "           1       0.00      0.00      0.00       100\n",
            "           2       0.20      1.00      0.33       164\n",
            "           3       0.00      0.00      0.00       110\n",
            "           4       1.00      0.01      0.01       152\n",
            "           5       0.00      0.00      0.00        95\n",
            "           6       0.00      0.00      0.00        97\n",
            "\n",
            "    accuracy                           0.20       822\n",
            "   macro avg       0.17      0.14      0.05       822\n",
            "weighted avg       0.22      0.20      0.07       822\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM4bvF0Bkmzn",
        "colab_type": "code",
        "outputId": "88610933-e1bc-4e2c-aa96-6628d325a725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_notes.size"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3270"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI2bquppQfMW",
        "colab_type": "code",
        "outputId": "4f7ae4f7-3aa0-46cd-ead9-1eabbb02cdb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "# notes, notes_test, target_notes, target_test = carrega_dados()\n",
        "\n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vetores de suporte\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Pegar tempo de execução\n",
        "inicio = time.time()\n",
        "\n",
        "# Aprendemos os dígitos na primeira metade dos dígitos\n",
        "\n",
        "classifier.fit(data, target_notes)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = classifier.predict(data_teste)\n",
        "\n",
        "fim = time.time()\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))\n",
        "\n",
        "print(f'Acurácia: {metrics.accuracy_score(expected, predicted)}\\n')\n",
        "\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "print(f'Tempo de execução: {fim - inicio}')\n",
        "\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       104\n",
            "           1       0.00      0.00      0.00       100\n",
            "           2       0.20      1.00      0.33       164\n",
            "           3       0.00      0.00      0.00       110\n",
            "           4       1.00      0.01      0.01       152\n",
            "           5       0.00      0.00      0.00        95\n",
            "           6       0.00      0.00      0.00        97\n",
            "\n",
            "    accuracy                           0.20       822\n",
            "   macro avg       0.17      0.14      0.05       822\n",
            "weighted avg       0.22      0.20      0.07       822\n",
            "\n",
            "\n",
            "Acurácia: 0.20072992700729927\n",
            "\n",
            "Matrix de confusão:\n",
            "[[  0   0 104   0   0   0   0]\n",
            " [  0   0 100   0   0   0   0]\n",
            " [  0   0 164   0   0   0   0]\n",
            " [  0   0 110   0   0   0   0]\n",
            " [  0   0 151   0   1   0   0]\n",
            " [  0   0  95   0   0   0   0]\n",
            " [  0   0  97   0   0   0   0]]\n",
            "Tempo de execução: 26.000375270843506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfVpYAwWZFD7",
        "colab_type": "text"
      },
      "source": [
        "#Algoritmo KNN_Notas\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM-OdfN3gVLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14b3cc45-c549-4be9-b7d2-7fa5e76c582e"
      },
      "source": [
        "print(notes.shape)\n",
        "print(notes_test.shape)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3270, 28, 28)\n",
            "(822, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrgoexHcYFre",
        "colab_type": "code",
        "outputId": "fba7ab48-e5c1-4810-9daa-8ad7a7e31d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "# Author: Christoffer de Paula Oliveira\n",
        "\n",
        "# Importando módulo que retorna os dados\n",
        "# import Dados\n",
        "\n",
        "# Importando Algoritmo SVM e Métricas para porcentagem de acertos e matriz de confusão.\n",
        "# from sklearn import neighbors, metrics\n",
        "\n",
        "# Importando Módulo prar obeter tempo de execução\n",
        "\n",
        "\n",
        "# Carregando as notas musicais (Similar a função load_digits)\n",
        "\n",
        "# notes, notes_test, target_notes, target_test = carrega_dados()\n",
        "\n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vizinhos mais próximos\n",
        "n_neighbors = 2\n",
        "\n",
        "X = data\n",
        "y = target_notes\n",
        "\n",
        "# Pegar tempo de execução\n",
        "inicio = time.time()\n",
        "\n",
        "for weights in ['uniform', 'distance']:\n",
        "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = clf.predict(data_teste)\n",
        "\n",
        "fim = time.time()\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (clf, metrics.classification_report(expected, predicted)))\n",
        "\n",
        "print(f'Acurácia: {metrics.accuracy_score(expected, predicted)}\\n')\n",
        "\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "print(f'Tempo de execução: {fim - inicio}')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
            "                     weights='distance'):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99       104\n",
            "           1       1.00      0.99      0.99       100\n",
            "           2       0.94      0.98      0.96       164\n",
            "           3       0.99      1.00      1.00       110\n",
            "           4       0.96      0.98      0.97       152\n",
            "           5       0.99      0.97      0.98        95\n",
            "           6       0.98      0.91      0.94        97\n",
            "\n",
            "    accuracy                           0.97       822\n",
            "   macro avg       0.98      0.97      0.97       822\n",
            "weighted avg       0.97      0.97      0.97       822\n",
            "\n",
            "\n",
            "Acurácia: 0.9732360097323601\n",
            "\n",
            "Matrix de confusão:\n",
            "[[102   0   1   0   0   0   1]\n",
            " [  1  99   0   0   0   0   0]\n",
            " [  0   0 160   0   4   0   0]\n",
            " [  0   0   0 110   0   0   0]\n",
            " [  0   0   2   0 149   0   1]\n",
            " [  0   0   2   1   0  92   0]\n",
            " [  0   0   6   0   2   1  88]]\n",
            "Tempo de execução: 4.993390798568726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsj5yRfQSzZA",
        "colab_type": "text"
      },
      "source": [
        "#Algoritmo Rede Neural_Notas\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcFTL-84TivQ",
        "colab_type": "code",
        "outputId": "6ab75f5d-7187-426b-f0bd-03ac771307e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nm1OAWET7u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEDU-X3GTqhn",
        "colab_type": "code",
        "outputId": "e1ed95d6-1a6b-4181-f4c6-29ada00eea83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo3k1W7LS5p0",
        "colab_type": "code",
        "outputId": "bb1d578d-6868-48ab-c180-1e39362b2f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "# import numpy as np\n",
        "import os # para criar pastas\n",
        "# import tensorflow as tf\n",
        "\n",
        "# criamos uma pasta para salvar o modelo\n",
        "# if not os.path.exists('tmp'): # se a pasta não existir\n",
        "#    os.makedirs('tmp') # cria a pasta\n",
        "\n",
        "# Importando módulo que retorna os dados\n",
        "# import Dados\n",
        "\n",
        "# Importando Métricas para porcentagem de acertos e matriz de confusão.\n",
        "from sklearn import metrics\n",
        "\n",
        "def accuracy(pred_y, true_y):\n",
        "    '''Compara dois vetores one-hot para produzir a acurácia'''\n",
        "\n",
        "    pred_labels = np.argmax(pred_y, 1)  # acha o dígito de maior prob. prevista\n",
        "    true_labels = np.argmax(true_y, 1)  # acha o dígito verdadeiro\n",
        "\n",
        "    return (pred_labels == true_labels).mean() * 100  # compara ambos\n",
        "\n",
        "\n",
        "# definindo constantes\n",
        "lr = 0.01  # taxa de aprendizado\n",
        "n_iter = 1000  # número de iterações de treino\n",
        "batch_size = 128  # qtd de imagens no mini-lote (para GDE)\n",
        "n_inputs = 24 * 24  # número de variáveis (pixeis)\n",
        "n_l1 = 512  # número de neurônios da primeira camada\n",
        "n_l2 = 512  # número de neurônios da segunda camada\n",
        "n_outputs = 7  # número classes (dígitos)\n",
        "\n",
        "# Peganod e dimencionando dados\n",
        "notes, notes_test, target_notes, target_test = carrega_dados()\n",
        "n_exemplos = len(notes)\n",
        "n_exemplos_teste = len(notes_test)\n",
        "data_sklearn = notes.reshape((n_exemplos, -1))\n",
        "data_sklearn_teste = notes_test.reshape((n_exemplos_teste, -1))\n",
        "\n",
        "graph = tf.Graph()  # cria um grafo\n",
        "with graph.as_default():  # abre o grafo para que possamos colocar nós\n",
        "\n",
        "    # Camadas de Inputs\n",
        "    with tf.name_scope('input_layer'):  # escopo de nome da camada de entrada\n",
        "        x_input = tf.placeholder(tf.float32, [None, n_inputs], name='images')\n",
        "        y_input = tf.placeholder(tf.int64, [None], name='labels')\n",
        "\n",
        "    # Camada 1\n",
        "    with tf.name_scope('first_layer'):  # escopo de nome da primeira camada\n",
        "        # variáveis da camada\n",
        "        W1 = tf.Variable(tf.truncated_normal([n_inputs, n_l1]), name='Weights')\n",
        "        b1 = tf.Variable(tf.zeros([n_l1]), name='bias')\n",
        "\n",
        "        l1 = tf.add(tf.matmul(x_input, W1), b1, name='linear_transformation')\n",
        "        l1 = tf.nn.relu(l1, name='relu')\n",
        "\n",
        "    # Camada 2\n",
        "    with tf.name_scope('second_layer'):  # escopo de nome da segunda camada\n",
        "        # variáveis da camada\n",
        "        W2 = tf.Variable(tf.truncated_normal([n_l1, n_l2]), name='Weights')\n",
        "        b2 = tf.Variable(tf.zeros([n_l2]), name='bias')\n",
        "\n",
        "        l2 = tf.add(tf.matmul(l1, W2), b2, name='linear_transformation')\n",
        "        l2 = tf.nn.relu(l2, name='relu')\n",
        "\n",
        "    # Camada de saída\n",
        "    with tf.name_scope('output_layer'):  # escopo de nome da camada de saída\n",
        "        # variáveis da camada\n",
        "        Wo = tf.Variable(tf.truncated_normal([n_l2, n_outputs]), name='Weights')\n",
        "        bo = tf.Variable(tf.zeros([n_outputs]), name='bias')\n",
        "\n",
        "        scores = tf.add(tf.matmul(l2, Wo), bo, name='linear_transformation')  # logits\n",
        "        y_hat = tf.nn.softmax(scores) # Converte scorer em probabilidades\n",
        "        error = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_input, logits=scores),\n",
        "            name='error')\n",
        "\n",
        "    # calcula acurácia\n",
        "    correct = tf.nn.in_top_k(scores, y_input, 1)  # calcula obs corretas (vetor bools V ou F)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))  # converte de bool para float32\n",
        "\n",
        "    # otimizador\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(error)\n",
        "\n",
        "    # inicializador\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # para salvar o modelo treinado\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "# abrimos a sessão tf\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    init.run()  # iniciamos as variáveis\n",
        "\n",
        "    # loop de treinamento\n",
        "    for step in range(n_iter + 1):\n",
        "\n",
        "        # cria os mini-lotes\n",
        "        x_batch = data_sklearn[: 200]\n",
        "        y_batch = target_notes[: 200]\n",
        "\n",
        "        # cria um feed_dict\n",
        "        feed_dict = {x_input: x_batch, y_input: y_batch}\n",
        "\n",
        "        # executa uma iteração de treino e calcula o erro\n",
        "        l, _ = sess.run([error, optimizer], feed_dict=feed_dict)\n",
        "\n",
        "        # mostra o progresso a cada 1000 iterações\n",
        "        if step % 1000 == 0:\n",
        "\n",
        "            # pega alguns dados de validação\n",
        "            x_valid = data_sklearn[: 100]\n",
        "            y_valid = target_test[: 100]\n",
        "\n",
        "            val_dict = {x_input: x_valid, y_input: y_valid}  # monta o feed_dict\n",
        "\n",
        "            # executa o nó para calcular a acurácia\n",
        "            error_np, acc = sess.run([error, accuracy], feed_dict=val_dict)\n",
        "\n",
        "            print('Erro de treino na iteração %d: %.2f' % (step, l))\n",
        "            print('Erro de validação na iteração %d: %.2f' % (step, error_np))\n",
        "            print('Acurácia de validação na iteração %d: %.2f\\n' % (step, acc))\n",
        "\n",
        "            # salva as variáveis do modelo\n",
        "            saver.save(sess, \"deep_ann.ckpt\")\n",
        "\n",
        "# restaurando modelo pra fazer previsões\n",
        "with tf.Session(graph=graph) as sess:\n",
        "    # restauramos o valor das variáveis\n",
        "    saver.restore(sess, \"deep_ann.ckpt\", )\n",
        "\n",
        "    x_test = data_sklearn_teste\n",
        "    y_test = target_test\n",
        "\n",
        "    val_dict = {x_input: x_test, y_input: y_test}\n",
        "    error_np, acc = sess.run([error, accuracy], feed_dict=val_dict)\n",
        "\n",
        "    classification = sess.run(tf.argmax(scores, 1), feed_dict={x_input: x_test})\n",
        "    print(acc)\n",
        "\n",
        "expected = y_test\n",
        "predicted = classification\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "       % (classification, metrics.classification_report(expected, predicted)))\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-d1593ebae751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Peganod e dimencionando dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotes_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_notes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarrega_dados\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mn_exemplos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mn_exemplos_teste\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotes_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'carrega_dados' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap9lg772YuGH",
        "colab_type": "text"
      },
      "source": [
        "#Gaussian Naive_Bayes\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUkJpuuAYbhf",
        "colab_type": "code",
        "outputId": "d9ce669c-dd41-4e83-eeba-f337e930770e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Author: Christoffer de Paula Oliveira\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Carregando as notas musicais (Similar a função load_digits)\n",
        "# = carrega_dados()\n",
        "notes, notes_test, target_notes, target_test \n",
        "\n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vetores de suporte\n",
        "classifier = GaussianNB()\n",
        "\n",
        "# Pegar tempo de execução\n",
        "inicio = time.time()\n",
        "\n",
        "# Aprendemos os dígitos na primeira metade dos dígitos\n",
        "\n",
        "classifier.fit(data, target_notes)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = classifier.predict(data_teste)\n",
        "\n",
        "fim = time.time()\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))\n",
        "\n",
        "print(f'Acurácia: {metrics.accuracy_score(expected, predicted)}\\n')\n",
        "\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "print(f'Tempo de execução: {fim - inicio}')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador GaussianNB(priors=None, var_smoothing=1e-09):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.88      0.86       104\n",
            "           1       0.78      0.91      0.84       100\n",
            "           2       0.88      0.80      0.84       164\n",
            "           3       0.83      0.94      0.88       110\n",
            "           4       0.89      0.78      0.84       152\n",
            "           5       0.82      0.73      0.77        95\n",
            "           6       0.78      0.86      0.81        97\n",
            "\n",
            "    accuracy                           0.84       822\n",
            "   macro avg       0.83      0.84      0.83       822\n",
            "weighted avg       0.84      0.84      0.84       822\n",
            "\n",
            "\n",
            "Acurácia: 0.8357664233576643\n",
            "\n",
            "Matrix de confusão:\n",
            "[[ 91   2   0   0   4   5   2]\n",
            " [  3  91   0   0   2   3   1]\n",
            " [  0   4 131  14   3   3   9]\n",
            " [  0   0   0 103   4   2   1]\n",
            " [ 11   7   9   1 119   1   4]\n",
            " [  0   7   6   6   0  69   7]\n",
            " [  3   6   3   0   1   1  83]]\n",
            "Tempo de execução: 0.04577231407165527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APYl_OFfaLRH",
        "colab_type": "text"
      },
      "source": [
        "#Multinominal Naive_Bayes\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfhCGVn4aKdz",
        "colab_type": "code",
        "outputId": "02563654-b25f-4b1e-c4e6-345297e3fb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Author: Christoffer de Paula Oliveira\n",
        "\n",
        "# # Importando módulo que retorna os dados\n",
        "# import Dados\n",
        "\n",
        "# # Importando Algoritmo SVM e Métricas para porcentagem de acertos e matriz de confusão.\n",
        "# from sklearn import metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Importando Módulo prar obeter tempo de execução\n",
        "import time\n",
        "\n",
        "# Carregando as notas musicais (Similar a função load_digits)\n",
        "# = carrega_dados()\n",
        "\n",
        "notes, notes_test, target_notes, target_test \n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vetores de suporte\n",
        "classifier = MultinomialNB()\n",
        "\n",
        "# Pegar tempo de execução\n",
        "inicio = time.time()\n",
        "\n",
        "# Aprendemos os dígitos na primeira metade dos dígitos\n",
        "\n",
        "classifier.fit(data, target_notes)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = classifier.predict(data_teste)\n",
        "\n",
        "fim = time.time()\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))\n",
        "\n",
        "print(f'Acurácia: {metrics.accuracy_score(expected, predicted)}\\n')\n",
        "\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "print(f'Tempo de execução: {fim - inicio}')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.79      0.82       104\n",
            "           1       0.80      0.87      0.83       100\n",
            "           2       0.86      0.88      0.87       164\n",
            "           3       0.95      0.91      0.93       110\n",
            "           4       0.86      0.84      0.85       152\n",
            "           5       0.86      0.69      0.77        95\n",
            "           6       0.72      0.90      0.80        97\n",
            "\n",
            "    accuracy                           0.84       822\n",
            "   macro avg       0.84      0.84      0.84       822\n",
            "weighted avg       0.85      0.84      0.84       822\n",
            "\n",
            "\n",
            "Acurácia: 0.843065693430657\n",
            "\n",
            "Matrix de confusão:\n",
            "[[ 82   4   3   1   6   3   5]\n",
            " [  2  87   2   0   5   1   3]\n",
            " [  2   6 144   0   2   4   6]\n",
            " [  0   0   0 100   5   2   3]\n",
            " [  7   3   5   0 127   0  10]\n",
            " [  1   7  10   4   1  66   6]\n",
            " [  1   2   4   0   2   1  87]]\n",
            "Tempo de execução: 0.06305480003356934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOXehSlHYTT-",
        "colab_type": "text"
      },
      "source": [
        "#Complement Naive_Bayes\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1XVy_D4YEY_",
        "colab_type": "code",
        "outputId": "7ff6d47f-ab94-4a31-badf-d556218b8c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Carregando as notas musicais (Similar a função load_digits)\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "# = carrega_dados()\n",
        "notes, notes_test, target_notes, target_test \n",
        "\n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vetores de suporte\n",
        "classifier = ComplementNB()\n",
        "\n",
        "# Pegar tempo de execução\n",
        "inicio = time.time()\n",
        "\n",
        "# Aprendemos os dígitos na primeira metade dos dígitos\n",
        "\n",
        "classifier.fit(data, target_notes)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = classifier.predict(data_teste)\n",
        "\n",
        "fim = time.time()\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))\n",
        "\n",
        "print(f'Acurácia: {metrics.accuracy_score(expected, predicted)}\\n')\n",
        "\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "print(f'Tempo de execução: {fim - inicio}')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.79      0.76       104\n",
            "           1       0.66      0.90      0.76       100\n",
            "           2       0.79      0.90      0.84       164\n",
            "           3       0.83      0.95      0.89       110\n",
            "           4       0.96      0.60      0.74       152\n",
            "           5       0.80      0.66      0.72        95\n",
            "           6       0.84      0.75      0.79        97\n",
            "\n",
            "    accuracy                           0.79       822\n",
            "   macro avg       0.80      0.79      0.79       822\n",
            "weighted avg       0.81      0.79      0.79       822\n",
            "\n",
            "\n",
            "Acurácia: 0.791970802919708\n",
            "\n",
            "Matrix de confusão:\n",
            "[[ 82   9   1   2   1   8   1]\n",
            " [  2  90   5   1   1   0   1]\n",
            " [  2  10 147   0   1   3   1]\n",
            " [  0   0   2 105   0   2   1]\n",
            " [ 21  17  11   6  91   0   6]\n",
            " [  1   7  10  10   0  63   4]\n",
            " [  5   3   9   3   1   3  73]]\n",
            "Tempo de execução: 0.05565786361694336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiHZhhaCXwWR",
        "colab_type": "text"
      },
      "source": [
        "#Bernoulli Naive_Bayes\n",
        "**Author:** Christoffer de Paula Oliveira"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTFicEBBUB3S",
        "colab_type": "code",
        "outputId": "3eb025b6-b6ff-4f16-8406-4bb0cdd0189d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# # Importando módulo que retorna os dados\n",
        "# import Dados\n",
        "\n",
        "# Importando Algoritmo SVM e Métricas para porcentagem de acertos e matriz de confusão.\n",
        "# from sklearn import metrics\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# Importando Módulo prar obeter tempo de execução\n",
        "# import time\n",
        "\n",
        "# Carregando as notas musicais (Similar a função load_digits)\n",
        "# = carrega_dados()\n",
        "notes, notes_test, target_notes, target_test \n",
        "\n",
        "# Para aplicar um classificador a esses dados, precisamos nivelar a imagem para\n",
        "# transformar os dados em uma matriz (amostras, recurso):\n",
        "n_samples = len(notes)\n",
        "n_samples_teste = len(notes_test)\n",
        "\n",
        "data = notes.reshape((n_samples, -1))\n",
        "data_teste = notes_test.reshape((n_samples_teste, -1))\n",
        "\n",
        "# Criar um classificador: um classificador de vetores de suporte\n",
        "classifier = BernoulliNB()\n",
        "\n",
        "# Pegar tempo de execução\n",
        "inicio = time.time()\n",
        "\n",
        "# Aprendemos os dígitos na primeira metade dos dígitos\n",
        "\n",
        "classifier.fit(data, target_notes)\n",
        "\n",
        "# Aprendemos as notas para aprendizagem, ou seja, 70% dos dados\n",
        "\n",
        "# Agora, preveja as notas com o restante dos dados, isto é, 30%\n",
        "expected = target_test\n",
        "predicted = classifier.predict(data_teste)\n",
        "\n",
        "fim = time.time()\n",
        "\n",
        "print(\"Relatório de classificação para o classificador %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(expected, predicted)))\n",
        "\n",
        "print(f'Acurácia: {metrics.accuracy_score(expected, predicted)}\\n')\n",
        "\n",
        "print(\"Matrix de confusão:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
        "\n",
        "print(f'Tempo de execução: {fim - inicio}')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Relatório de classificação para o classificador BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.73      0.80       104\n",
            "           1       0.83      0.88      0.85       100\n",
            "           2       0.82      0.85      0.84       164\n",
            "           3       0.98      0.94      0.96       110\n",
            "           4       0.82      0.86      0.84       152\n",
            "           5       0.80      0.72      0.76        95\n",
            "           6       0.77      0.87      0.82        97\n",
            "\n",
            "    accuracy                           0.84       822\n",
            "   macro avg       0.84      0.83      0.84       822\n",
            "weighted avg       0.84      0.84      0.84       822\n",
            "\n",
            "\n",
            "Acurácia: 0.8394160583941606\n",
            "\n",
            "Matrix de confusão:\n",
            "[[ 76   1   6   1  11   5   4]\n",
            " [  2  88   2   0   5   1   2]\n",
            " [  1   6 140   0   5   6   6]\n",
            " [  0   0   1 103   3   2   1]\n",
            " [  5   5   5   0 131   1   5]\n",
            " [  0   4  12   1   3  68   7]\n",
            " [  2   2   5   0   2   2  84]]\n",
            "Tempo de execução: 0.07756876945495605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlcjmsDQe-W5",
        "colab_type": "text"
      },
      "source": [
        "#Nova Rede Neural \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1jEQQ11bhNu",
        "colab_type": "code",
        "outputId": "c208e8b8-6f8d-4adb-98d6-297e19e7c93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.exceptions import NotFittedError\n",
        "from datetime import datetime\n",
        "\n",
        "# He et al. initialization from https://arxiv.org/abs/1502.01852\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "\n",
        "\n",
        "# This class inherits from Sklearn's BaseEstimator and ClassifierMixin\n",
        "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, n_hidden_layers=4, n_neurons=50, optimizer_class=tf.train.AdamOptimizer, learning_rate=0.01,\n",
        "                 batch_size=20, activation=tf.nn.elu, initializer=he_init, batch_norm_momentum=None, dropout_rate=None,\n",
        "                 max_checks_without_progress=20, show_progress=10, tensorboard_logdir=None, random_state=None):\n",
        "\n",
        "        # Initialize the class with sensible default hyperparameters\n",
        "        self.n_hidden_layers = n_hidden_layers\n",
        "        self.n_neurons = n_neurons\n",
        "        self.optimizer_class = optimizer_class\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.activation = activation\n",
        "        self.initializer = initializer\n",
        "        self.batch_norm_momentum = batch_norm_momentum\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.max_checks_without_progress = max_checks_without_progress\n",
        "        self.show_progress = show_progress\n",
        "        self.random_state = random_state\n",
        "        self.tensorboard_logdir = tensorboard_logdir\n",
        "        self._session = None  # Instance variables preceded by _ are private members\n",
        "\n",
        "    def _dnn(self, inputs):\n",
        "        '''This method builds the hidden layers and\n",
        "         Provides for implementation of batch normalization and dropout'''\n",
        "\n",
        "        for layer in range(self.n_hidden_layers):\n",
        "\n",
        "            # Apply dropout if specified\n",
        "            if self.dropout_rate:\n",
        "                inputs = tf.layers.dropout(inputs, rate=self.dropout_rate, training=self._training)\n",
        "            # Create the hidden layer\n",
        "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
        "                                     activation=self.activation,\n",
        "                                     kernel_initializer=self.initializer,\n",
        "                                     name=\"hidden{}\".format(layer + 1))\n",
        "\n",
        "            # Apply batch normalization if specified\n",
        "            if self.batch_norm_momentum:\n",
        "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
        "                                                       training=self._training)\n",
        "\n",
        "            # Apply activation function\n",
        "            inputs = self.activation(inputs, name=\"hidden{}_out\".format(layer+1))\n",
        "        return inputs\n",
        "\n",
        "    def _construct_graph(self, n_inputs, n_outputs):\n",
        "        '''This method builds the complete Tensorflow computation graph\n",
        "            n_inputs: number of features\n",
        "            n_outputs: number of classes\n",
        "        '''\n",
        "\n",
        "        if self.random_state:\n",
        "            tf.set_random_seed(self.random_state)\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "        # Placeholders for training data, labels are class exclusive integers\n",
        "        X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
        "        y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
        "\n",
        "        # Create a training placeholder\n",
        "        if self.batch_norm_momentum or self.dropout_rate:\n",
        "            self._training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
        "        else:\n",
        "            self._training = None\n",
        "\n",
        "        # Output after hidden layers\n",
        "        pre_output = self._dnn(X)\n",
        "\n",
        "        # Outputs from output layer\n",
        "        logits = tf.layers.dense(pre_output, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
        "        probabilities = tf.nn.softmax(logits, name=\"probabilities\")\n",
        "\n",
        "        ''' Cost function is cross entropy and loss is average cross entropy. Sparse softmax must be used because shape \n",
        "        of logits is [None, n_classes] and shape of labels is [None]'''\n",
        "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "        '''Optimizer and training operation. The control dependency is necessary for implementing batch normalization. \n",
        "        The training operation must be dependent on the batch normalization.'''\n",
        "\n",
        "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
        "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "        with tf.control_dependencies(update_ops):\n",
        "            training_op = optimizer.minimize(loss)\n",
        "\n",
        "        # Metrics for evaluation\n",
        "        correct = tf.nn.in_top_k(logits, y, 1)\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct, tf. float32),name=\"accuracy\")\n",
        "\n",
        "        # Initializer and saver\n",
        "        init = tf.global_variables_initializer()\n",
        "        saver = tf.train.Saver()\n",
        "\n",
        "        if self.tensorboard_logdir:\n",
        "            now = datetime.utcnow().strftime('%Y%m%d-%H%M%S')\n",
        "            tb_logdir = self.tensorboard_logdir + \"/run-{}\".format(now)\n",
        "            cost_summary = tf.summary.scalar(\"validation_loss\", loss)\n",
        "            acc_summary = tf.summary.scalar(\"validation_accuracy\", accuracy)\n",
        "            merged_summary = tf.summary.merge_all()\n",
        "            file_writer = tf.summary.FileWriter(tb_logdir, tf.get_default_graph())\n",
        "\n",
        "            self._merged_summary = merged_summary\n",
        "            self._file_writer = file_writer\n",
        "\n",
        "        self._X, self._y = X, y\n",
        "        self._logits = logits\n",
        "        self._probabilities = probabilities\n",
        "        self._loss = loss\n",
        "        self._training_op = training_op\n",
        "        self._accuracy = accuracy\n",
        "        self._init, self._saver = init, saver\n",
        "\n",
        "    def close_session(self):\n",
        "        if self._session:\n",
        "            self._session.close()\n",
        "\n",
        "    def _get_model_parameters(self):\n",
        "        # Retrieves the value of all the variables in the network\n",
        "        with self._graph.as_default():\n",
        "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
        "        return {gvar.op.name: value for gvar, value in\n",
        "                zip(gvars, self._session.run(gvars))}\n",
        "\n",
        "    def _restore_model_parameters(self, model_params):\n",
        "        # Restores the value of all variables using tf assign operations\n",
        "        # First retrieve the list of all the graph variables\n",
        "        gvar_names = list(model_params.keys())\n",
        "\n",
        "        # Then retrieve all the assignment operations in the graph\n",
        "        assign_ops = {gvar_name: self._graph.get_operation_by_name( gvar_name + \"/Assign\") for gvar_name in gvar_names}\n",
        "\n",
        "        # Fetch the initialization values of the assignment operations\n",
        "        '''graph.get_operation_by_name(operation).inputs returns the input to the given operation; because these are all\n",
        "         assignment operations, the second argument to inputs is the value assigned to the variable'''\n",
        "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op \t\t\t  in assign_ops.items()}\n",
        "        # Create a dictionary mapping initial values to values after training\n",
        "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
        "        # Assign the trained value to all the variables in the graph\n",
        "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
        "\n",
        "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
        "        # Method to train the model. Implements early stopping if validation data is provided\n",
        "\n",
        "        self.close_session()\n",
        "        n_inputs = X.shape[1] # Number of features\n",
        "\n",
        "        # If labels are provided in one_hot form, convert to integer class labels\n",
        "        y = np.array(y)\n",
        "        y_valid = np.array(y_valid)\n",
        "\n",
        "        if len(y.shape) == 2:\n",
        "            y = np.argmax(y, axis=1)\n",
        "\n",
        "        if len(y_valid.shape) == 2:\n",
        "            y_valid = np.argmax(y_valid, axis=1)\n",
        "\n",
        "        self.classes_ = np.unique(y)\n",
        "        n_outputs = len(self.classes_) # Number of classes\n",
        "\n",
        "        # Tensorflow expects labels from 0 to n_classes - 1.\n",
        "        self.class_to_index_ = {label: index for index, label in enumerate(self.classes_)}\n",
        "        labels = [self.class_to_index_[label] for label in y]\n",
        "        y = np.array(labels, dtype=np.int32)\n",
        "\n",
        "        self._graph = tf.Graph()\n",
        "\n",
        "        # Build the computation graph with self as default graph\n",
        "        with self._graph.as_default():\n",
        "            self._construct_graph(n_inputs, n_outputs)\n",
        "\n",
        "        # Early stopping parameters\n",
        "        checks_without_progress = 0\n",
        "        best_loss = np.float(\"inf\")\n",
        "        best_parameters = None\n",
        "\n",
        "        self._session = tf.Session(graph=self._graph)\n",
        "\n",
        "        with self._session.as_default() as sess:\n",
        "            # Initialize all variables\n",
        "            self._init.run()\n",
        "            num_instances = X.shape[0] # Total number of training instances\n",
        "            for epoch in range(n_epochs):\n",
        "                rnd_idx = np.random.permutation(num_instances)\n",
        "                for rnd_indices in np.array_split(rnd_idx, num_instances // self.batch_size):\n",
        "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
        "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
        "                    if self._training is not None:\n",
        "                        feed_dict[self._training] = True\n",
        "                    train_acc, _ = sess.run([self._accuracy, self._training_op], \t\t\t\t\tfeed_dict)\n",
        "\n",
        "                # Early stopping implementation\n",
        "                if X_valid is not None and y_valid is not None:\n",
        "                    feed_dict_valid = {self._X: X_valid, self._y: y_valid}\n",
        "\n",
        "                    # Write summary for tensorboard\n",
        "                    if self.tensorboard_logdir:\n",
        "                        val_acc, val_loss, summary = sess.run([self._accuracy, self.\n",
        "                                                              _loss, self._merged_summary], feed_dict=feed_dict_valid)\n",
        "\n",
        "                        self._file_writer.add_summary(summary, epoch)\n",
        "\n",
        "                    else:\n",
        "                        val_acc, val_loss = sess.run([self._accuracy, self._loss], feed_dict=feed_dict_valid)\n",
        "\n",
        "                    # Show training progress every show_progress epochs\n",
        "                    if self.show_progress:\n",
        "                        if epoch % self.show_progress == 0:\n",
        "                            print(\"Epoch: {} Current training accuracy: {:.4f} Validation Accuracy: {:.4f} Validation Loss {:.6f}\".format(\n",
        "                                epoch+1, train_acc, val_acc, val_loss))\n",
        "\n",
        "                    # Check to see if model is improving\n",
        "                    if val_loss < best_loss:\n",
        "                        best_loss = val_loss\n",
        "                        checks_without_progress = 0\n",
        "                        best_parameters = self._get_model_parameters()\n",
        "                    else:\n",
        "                        checks_without_progress += 1\n",
        "\n",
        "                    if checks_without_progress > self.max_checks_without_progress:\n",
        "                        print(\"Stopping Early! Loss has not improved in {} epochs\".format(\n",
        "                            self.max_checks_without_progress))\n",
        "                        break\n",
        "\n",
        "                # No validation set provided\n",
        "                else:\n",
        "                    if self.show_progress:\n",
        "                        if epoch % self.show_progress == 0:\n",
        "                            print(\"Epoch: {} Current training accuracy: {:.4f}\".format(\n",
        "                                epoch+1, train_acc))\n",
        "\n",
        "            # In the case of early stopping, restore the best weight values\n",
        "            if best_parameters:\n",
        "                self._restore_model_parameters(best_parameters)\n",
        "                return self\n",
        "\n",
        "    def predict_probabilities(self, X):\n",
        "        # Predict the probabilities of each class\n",
        "        if not self._session:\n",
        "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
        "        with self._session.as_default() as sess:\n",
        "            return self._probabilities.eval(feed_dict={self._X: X})\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict the classes themselves and return with shape=(None,)\n",
        "        class_indices = np.argmax(self.predict_probabilities(X), axis=1)\n",
        "        predictions = np.array([[self.classes_[class_index]] for class_index in class_indices], dtype=np.int32)\n",
        "        return np.reshape(predictions, (-1,))\n",
        "\n",
        "    def save(self, path):\n",
        "        # Save the model to provided path\n",
        "        self._saver.save(self._session, path)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2o-HH8DauR4",
        "colab_type": "code",
        "outputId": "a3290f01-794b-4a3b-c034-d6ad03133cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# from dnn_classifier import DNNClassifier\n",
        "# import Dados\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Carregando as notas musicais (Similar a função load_digits)\n",
        "\n",
        "# notes, notes_test, target_notes, target_test = carrega_dados()\n",
        "\n",
        "# notes, notes_test, target_notes, target_test \n",
        "n_exemplos = len(notes)\n",
        "n_exemplos_teste = len(notes_test)\n",
        "data_sklearn = notes.reshape((n_exemplos, -1))\n",
        "data_sklearn_teste = notes_test.reshape((n_exemplos_teste, -1))\n",
        "\n",
        "X_train = data_sklearn\n",
        "y_train = target_notes\n",
        "\n",
        "X_validation = data_sklearn[: 100]\n",
        "y_validation = data_sklearn_teste[: 100]\n",
        "\n",
        "X_test = data_sklearn_teste\n",
        "y_test = target_test\n",
        "\n",
        "dnn = DNNClassifier(show_progress=None, random_state=42)\n",
        "\n",
        "parameter_distributions = {\n",
        "    'n_hidden_layers': [3, 4, 5],\n",
        "    'n_neurons': [40, 50, 100],\n",
        "    'batch_size': [64, 128]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(dnn, parameter_distributions, n_iter=15, scoring='accuracy', verbose=2)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_notas_dnn = random_search.best_estimator_\n",
        "mnist_predictions = best_notas_dnn.predict(X_test)\n",
        "\n",
        "print(\"Accuracy on test set: {:.2f}%\".format(accuracy_score(y_test, mnist_predictions) * 100))\n",
        "\n",
        "print(random_search.best_params_)\n",
        "\n",
        "\n",
        "random_search.best_estimator_.save(\"models/mnist_random_best_model\")\n",
        "\n",
        "'''parameter_grid = {\n",
        "    'n_hidden_layers': [3],\n",
        "    'n_neurons': [75, 100, 125, 150],\n",
        "    'batch_size': [64],\n",
        "    'learning_rate':[0.005],\n",
        "    'activation': [tf.nn.elu],\n",
        "    'max_checks_without_progress': [20, 25],\n",
        "    'batch_norm_momentum': [0.9, 0.95],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(dnn, parameter_grid, scoring='accuracy', verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "grid_search.best_params_\n",
        "predictions = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "print(\"Score on test set: {:.2f}%\".format(accuracy_score(y_test, predictions) * 100))\n",
        "\n",
        "random_search.best_estimator_.save(\"models/mnist_grid_best_model\")'''\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=128 ................\n",
            "WARNING:tensorflow:From <ipython-input-79-10dc7063a244>:46: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . n_neurons=100, n_hidden_layers=3, batch_size=128, total=   8.3s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=128 ................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] . n_neurons=100, n_hidden_layers=3, batch_size=128, total=   7.8s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=3, batch_size=128, total=   8.1s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=3, batch_size=128, total=   7.9s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=3, batch_size=128, total=   7.7s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=4, batch_size=128, total=   5.6s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=4, batch_size=128, total=   5.4s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=4, batch_size=128, total=   5.7s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=4, batch_size=128, total=   6.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=4, batch_size=128, total=   6.0s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=4, batch_size=64, total=  12.6s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=4, batch_size=64, total=  12.6s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=4, batch_size=64, total=  11.5s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=4, batch_size=64, total=  12.4s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=4, batch_size=64, total=  12.5s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=3, batch_size=128, total=   5.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=3, batch_size=128, total=   5.2s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=3, batch_size=128, total=   5.2s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=3, batch_size=128, total=   5.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=3, batch_size=128, total=   5.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=5, batch_size=64, total=   8.4s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=5, batch_size=64, total=   8.5s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=5, batch_size=64, total=   8.4s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=5, batch_size=64, total=   8.4s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=5, batch_size=64, total=   8.4s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=5, batch_size=128, total=   6.2s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=5, batch_size=128, total=   6.0s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=5, batch_size=128, total=   6.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=5, batch_size=128, total=   6.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=40, n_hidden_layers=5, batch_size=128, total=   6.0s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=50, n_hidden_layers=5, batch_size=128, total=   7.5s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=50, n_hidden_layers=5, batch_size=128, total=   7.3s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=50, n_hidden_layers=5, batch_size=128, total=   7.5s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=50, n_hidden_layers=5, batch_size=128, total=   7.3s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=128 .................\n",
            "[CV] .. n_neurons=50, n_hidden_layers=5, batch_size=128, total=   7.5s\n",
            "[CV] n_neurons=100, n_hidden_layers=5, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=5, batch_size=128, total=  10.7s\n",
            "[CV] n_neurons=100, n_hidden_layers=5, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=5, batch_size=128, total=  10.1s\n",
            "[CV] n_neurons=100, n_hidden_layers=5, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=5, batch_size=128, total=  10.6s\n",
            "[CV] n_neurons=100, n_hidden_layers=5, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=5, batch_size=128, total=  10.5s\n",
            "[CV] n_neurons=100, n_hidden_layers=5, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=5, batch_size=128, total=  10.5s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=4, batch_size=64, total=   7.9s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=4, batch_size=64, total=   8.1s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=4, batch_size=64, total=   7.8s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=4, batch_size=64, total=   7.9s\n",
            "[CV] n_neurons=40, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=4, batch_size=64, total=   7.8s\n",
            "[CV] n_neurons=50, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=3, batch_size=64, total=   8.3s\n",
            "[CV] n_neurons=50, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=3, batch_size=64, total=   8.5s\n",
            "[CV] n_neurons=50, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=3, batch_size=64, total=   8.3s\n",
            "[CV] n_neurons=50, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=3, batch_size=64, total=   8.3s\n",
            "[CV] n_neurons=50, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=3, batch_size=64, total=   8.0s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=3, batch_size=64, total=   7.3s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=3, batch_size=64, total=   7.3s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=3, batch_size=64, total=   7.3s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=3, batch_size=64, total=   7.3s\n",
            "[CV] n_neurons=40, n_hidden_layers=3, batch_size=64 ..................\n",
            "[CV] ... n_neurons=40, n_hidden_layers=3, batch_size=64, total=   7.3s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=4, batch_size=128, total=   9.0s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=4, batch_size=128, total=   9.4s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=4, batch_size=128, total=   9.2s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=4, batch_size=128, total=   9.0s\n",
            "[CV] n_neurons=100, n_hidden_layers=4, batch_size=128 ................\n",
            "[CV] . n_neurons=100, n_hidden_layers=4, batch_size=128, total=   9.2s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=5, batch_size=64, total=   9.5s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=5, batch_size=64, total=   9.6s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=5, batch_size=64, total=   9.8s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=5, batch_size=64, total=   9.3s\n",
            "[CV] n_neurons=50, n_hidden_layers=5, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=5, batch_size=64, total=   9.7s\n",
            "[CV] n_neurons=50, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=4, batch_size=64, total=   8.9s\n",
            "[CV] n_neurons=50, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=4, batch_size=64, total=   9.0s\n",
            "[CV] n_neurons=50, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=4, batch_size=64, total=   9.0s\n",
            "[CV] n_neurons=50, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=4, batch_size=64, total=   9.0s\n",
            "[CV] n_neurons=50, n_hidden_layers=4, batch_size=64 ..................\n",
            "[CV] ... n_neurons=50, n_hidden_layers=4, batch_size=64, total=   9.0s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=3, batch_size=64, total=  11.1s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=3, batch_size=64, total=  11.0s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=3, batch_size=64, total=  10.5s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=3, batch_size=64, total=  10.9s\n",
            "[CV] n_neurons=100, n_hidden_layers=3, batch_size=64 .................\n",
            "[CV] .. n_neurons=100, n_hidden_layers=3, batch_size=64, total=  10.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 10.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 94.53%\n",
            "{'n_neurons': 100, 'n_hidden_layers': 3, 'batch_size': 64}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'parameter_grid = {\\n    \\'n_hidden_layers\\': [3],\\n    \\'n_neurons\\': [75, 100, 125, 150],\\n    \\'batch_size\\': [64],\\n    \\'learning_rate\\':[0.005],\\n    \\'activation\\': [tf.nn.elu],\\n    \\'max_checks_without_progress\\': [20, 25],\\n    \\'batch_norm_momentum\\': [0.9, 0.95],\\n}\\n\\ngrid_search = GridSearchCV(dnn, parameter_grid, scoring=\\'accuracy\\', verbose=2)\\ngrid_search.fit(X_train, y_train)\\n\\n\\ngrid_search.best_params_\\npredictions = grid_search.best_estimator_.predict(X_test)\\n\\nprint(\"Score on test set: {:.2f}%\".format(accuracy_score(y_test, predictions) * 100))\\n\\nrandom_search.best_estimator_.save(\"models/mnist_grid_best_model\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohrDBpRxava_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}